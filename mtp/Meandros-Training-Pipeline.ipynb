{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meandros Training Pipeline\n",
    "\n",
    "_Recommendations_:\n",
    "\n",
    "- Utilize a GPU for model training. Inference and testing can typically be performed using a CPU.\n",
    "- The Meandros models were trained using Google Colab with a Tesla K80 GPU (12 GB RAM).\n",
    "- This pipeline is configured for the gastruloid model; however, by updating the class names and adding new images, it can be easily adapted to train any model compatible with Meandros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Setup Train and Test Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'train/'\n",
    "TEST_PATH = 'val/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Define a class that will be used as base to be detected by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import utils\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class GastruloidsDataset(utils.Dataset):\n",
    "\n",
    "    def load_gastruloid(self, dataset_dir):\n",
    "        self.add_class(\"gastruloid_roi\", 1, \"gastruloid_roi\")\n",
    "        # assert subset in [\"train\", \"val\"]\n",
    "        # dataset_dir = os.path.join(dataset_dir, subset)\n",
    "        for d in os.listdir(dataset_dir):\n",
    "          number_images = d[-7:]\n",
    "          annotations = json.load(open(os.path.join(os.path.join(dataset_dir,d), f\"\"\"Correct_Annotations.json\"\"\")))\n",
    "          annotations = list(annotations.values())\n",
    "          annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Add images\n",
    "          for a in annotations:\n",
    "              for js in a.get('regions'):\n",
    "                st = js.get('region_attributes')\n",
    "                if st:\n",
    "                  if st.get('name').get('ROI'):\n",
    "                    polygons = [js['shape_attributes']] \n",
    "                    image_path = os.path.join(os.path.join(dataset_dir,d), a['filename'])\n",
    "                    image = skimage.io.imread(image_path)\n",
    "                    height, width = image.shape[:2]\n",
    "\n",
    "              self.add_image(\n",
    "                  \"gastruloid_roi\",\n",
    "                  image_id=a['filename'],  # use file name as a unique image id\n",
    "                  path=image_path,\n",
    "                  width=width, height=height,\n",
    "                  polygons=polygons)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"gastruloid_roi\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        return mask.astype(np.bool_), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"axol_leg\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Load the Datasets of train and test in the path defined in Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug\n",
    "\n",
    "dataset_train = GastruloidsDataset()\n",
    "dataset_train.load_gastruloid(TRAIN_PATH)\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = GastruloidsDataset()\n",
    "dataset_val.load_gastruloid(TEST_PATH)\n",
    "dataset_val.prepare()\n",
    "\n",
    "augmentation = imgaug.augmenters.Fliplr(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Setup the configuration class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "\n",
    "class GastruloidsConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"gastruloids_roi\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + axol_leg\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = len(dataset_train.image_ids)\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "    BATCH_SIZE = 2\n",
    "\n",
    "    \n",
    "config = GastruloidsConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Download a base model using COCO (to obtain better results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(\"mask_rcnn_coco.h5\")\n",
    "#Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "   utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "#utils.download_trained_weights(COCO_MODEL_PATH) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Load the weights and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import model as modellib\n",
    "\n",
    "MODEL_DIR = \"logs\"  # Directory for logs and checkpoints\n",
    "WEIGHTS_PATH = \"model_name.h5\" # Initial weights file\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                            \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=100, \n",
    "            layers='heads')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 - Setup an Inference class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as modellib\n",
    "import utils\n",
    "\n",
    "class InferenceConfig(GastruloidsConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "\n",
    "MODEL_DIR = \"logs\"  # Directory for logs and checkpoints\n",
    "WEIGHTS_PATH = \"mask_rcnn_gastruloids_roi_001.h5\"\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "model_path = os.path.join(\"mask_rcnn_gastruloids_roi_0001.h5\")\n",
    "#model_path = model.find_last()[1]\n",
    "\n",
    "print(model_path)\n",
    "\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "from model import log\n",
    "import random\n",
    "import visualize\n",
    "\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "# visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "\n",
    "visualize.display_top_masks(original_image, gt_mask, gt_class_id, dataset_val.class_names, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_masks_for_comparison(pred_masks, gt_masks, gt_bbox, image_shape):\n",
    "    \"\"\"\n",
    "    Prepare masks for comparison by ensuring they're at the same resolution\n",
    "    \"\"\"\n",
    "    # Ensure masks are 3D (height, width, instances)\n",
    "    if len(pred_masks.shape) == 2:\n",
    "        pred_masks = np.expand_dims(pred_masks, axis=-1)\n",
    "    if len(gt_masks.shape) == 2:\n",
    "        gt_masks = np.expand_dims(gt_masks, axis=-1)\n",
    "        \n",
    "    if gt_masks.shape[:2] != pred_masks.shape[:2]:\n",
    "        # If ground truth is mini mask, expand it\n",
    "        if gt_masks.shape[:2] == (56, 56):  # MINI_MASK_SHAPE\n",
    "            # Expand ground truth mini-mask to full size\n",
    "            full_masks = np.zeros((*image_shape[:2], gt_masks.shape[-1]), dtype=bool)\n",
    "            for i in range(gt_masks.shape[-1]):\n",
    "                # For single instance, pass the mask directly\n",
    "                y1, x1, y2, x2 = gt_bbox[i]\n",
    "                h = y2 - y1\n",
    "                w = x2 - x1\n",
    "                # Resize the mini mask to the bbox size\n",
    "                m = skimage.transform.resize(gt_masks[:, :, i].astype(float), (h, w), order=1)\n",
    "                # Place the resized mask in the full image\n",
    "                full_masks[y1:y2, x1:x2, i] = m >= 0.5\n",
    "            gt_masks = full_masks\n",
    "    \n",
    "    return pred_masks, gt_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = np.random.choice(dataset_val.image_ids)\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(\n",
    "    dataset_val, inference_config, image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([image], verbose=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['masks'], gt_mask = prepare_masks_for_comparison(\n",
    "    results['masks'], \n",
    "    gt_mask,\n",
    "    gt_bbox,\n",
    "    image.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After preparation:\")\n",
    "print(\"Ground truth mask shape:\", gt_mask.shape)\n",
    "print(\"Predicted mask shape:\", results['masks'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Plot ground truth\n",
    "    visualize.display_instances(\n",
    "        image=image,\n",
    "        boxes=gt_bbox,\n",
    "        masks=gt_mask,\n",
    "        class_ids=gt_class_id,\n",
    "        class_names=dataset_val.class_names,\n",
    "        title=\"Ground Truth\",\n",
    "        ax=ax[0]\n",
    "    )\n",
    "    \n",
    "    # Plot predictions\n",
    "    visualize.display_instances(\n",
    "        image=image,\n",
    "        boxes=results['rois'],\n",
    "        masks=results['masks'],\n",
    "        class_ids=results['class_ids'],\n",
    "        class_names=dataset_val.class_names,\n",
    "        scores=results['scores'],\n",
    "        title=\"Predictions\",\n",
    "        ax=ax[1]\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Calculate and display IoU scores\n",
    "    overlaps = utils.compute_overlaps_masks(results['masks'], gt_mask)\n",
    "    print(\"\\nMask IoU Scores:\")\n",
    "    for i in range(len(results['scores'])):\n",
    "        print(f\"Prediction {i+1}:\")\n",
    "        print(f\"  Confidence Score: {results['scores'][i]:.3f}\")\n",
    "        print(f\"  IoU with Ground Truth: {overlaps[i][0]:.3f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Error occurred:\", e)\n",
    "    print(\"\\nDetailed mask information:\")\n",
    "    print(\"Ground truth mask - Shape:\", gt_mask.shape, \"Type:\", gt_mask.dtype)\n",
    "    print(\"Predicted mask - Shape:\", results['masks'].shape, \"Type:\", results['masks'].dtype)\n",
    "    print(\"Number of GT instances:\", len(gt_class_id))\n",
    "    print(\"Number of predicted instances:\", len(results['class_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_predictions(model, dataset, num_images=2):\n",
    "    \"\"\"\n",
    "    Analyze predictions across multiple images and display results\n",
    "    \"\"\"\n",
    "    # Get random image ids\n",
    "    image_ids = np.random.choice(dataset.image_ids, min(num_images, len(dataset.image_ids)), replace=False)\n",
    "    \n",
    "    # Store results\n",
    "    all_ious = []\n",
    "    all_scores = []\n",
    "    \n",
    "    for idx, image_id in enumerate(image_ids):\n",
    "        # Load image and ground truth\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(\n",
    "            dataset, inference_config, image_id)\n",
    "        \n",
    "        # Get predictions\n",
    "        results = model.detect([image], verbose=0)[0]\n",
    "        \n",
    "        # Prepare masks for comparison\n",
    "        results['masks'], gt_mask = prepare_masks_for_comparison(\n",
    "            results['masks'], \n",
    "            gt_mask,\n",
    "            gt_bbox,\n",
    "            image.shape\n",
    "        )\n",
    "        \n",
    "        # Create figure and axes\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        \n",
    "        # Plot ground truth\n",
    "        visualize.display_instances(\n",
    "            image=image.copy(),\n",
    "            boxes=gt_bbox,\n",
    "            masks=gt_mask,\n",
    "            class_ids=gt_class_id,\n",
    "            class_names=dataset.class_names,\n",
    "            title=f\"Ground Truth (Image {idx + 1})\",\n",
    "            ax=ax1\n",
    "        )\n",
    "        \n",
    "        # Plot predictions\n",
    "        visualize.display_instances(\n",
    "            image=image.copy(),\n",
    "            boxes=results['rois'],\n",
    "            masks=results['masks'],\n",
    "            class_ids=results['class_ids'],\n",
    "            class_names=dataset.class_names,\n",
    "            scores=results['scores'],\n",
    "            title=f\"Predictions (Image {idx + 1})\",\n",
    "            ax=ax2\n",
    "        )\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate IoU scores\n",
    "        overlaps = utils.compute_overlaps_masks(results['masks'], gt_mask)\n",
    "        \n",
    "        print(f\"\\nResults for Image {idx + 1}:\")\n",
    "        print(\"-\" * 50)\n",
    "        for i in range(len(results['scores'])):\n",
    "            iou = overlaps[i][0]\n",
    "            score = results['scores'][i]\n",
    "            print(f\"Prediction {i+1}:\")\n",
    "            print(f\"  Confidence Score: {score:.3f}\")\n",
    "            print(f\"  IoU with Ground Truth: {iou:.3f}\")\n",
    "            \n",
    "            all_ious.append(iou)\n",
    "            all_scores.append(score)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Number of images analyzed: {len(image_ids)}\")\n",
    "    print(f\"Average IoU: {np.mean(all_ious):.3f} ± {np.std(all_ious):.3f}\")\n",
    "    print(f\"Average Confidence Score: {np.mean(all_scores):.3f} ± {np.std(all_scores):.3f}\")\n",
    "    \n",
    "    # Plot IoU distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(all_ious, bins=20, range=(0, 1), alpha=0.7)\n",
    "    plt.title(\"Distribution of IoU Scores\")\n",
    "    plt.xlabel(\"IoU Score\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot Confidence vs IoU\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(all_scores, all_ious, alpha=0.5)\n",
    "    plt.title(\"Confidence Score vs IoU\")\n",
    "    plt.xlabel(\"Confidence Score\")\n",
    "    plt.ylabel(\"IoU Score\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return all_ious, all_scores\n",
    "\n",
    "# Run the analysis\n",
    "all_ious, all_scores = analyze_predictions(model, dataset_val, num_images=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_test_and_val_predictions(model, dataset_test, dataset_val, num_images=2):\n",
    "    \"\"\"\n",
    "    Compare predictions between test and validation sets\n",
    "    \"\"\"\n",
    "    # Get random image ids from both datasets\n",
    "    test_image_ids = np.random.choice(dataset_test.image_ids, num_images, replace=False)\n",
    "    val_image_ids = np.random.choice(dataset_val.image_ids, num_images, replace=False)\n",
    "    \n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "    \n",
    "    # Process test images\n",
    "    for idx, image_id in enumerate(test_image_ids):\n",
    "        # Load image and ground truth\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(\n",
    "            dataset_test, inference_config, image_id)\n",
    "        \n",
    "        # Get predictions\n",
    "        results = model.detect([image], verbose=0)[0]\n",
    "        \n",
    "        # Prepare masks for comparison\n",
    "        results['masks'], gt_mask = prepare_masks_for_comparison(\n",
    "            results['masks'], \n",
    "            gt_mask,\n",
    "            gt_bbox,\n",
    "            image.shape\n",
    "        )\n",
    "        \n",
    "        # Calculate IoU scores\n",
    "        overlaps = utils.compute_overlaps_masks(results['masks'], gt_mask)\n",
    "        iou_score = overlaps[0][0] if len(overlaps) > 0 else 0\n",
    "        \n",
    "        # Plot ground truth and predictions side by side\n",
    "        ax = axes[0, idx]\n",
    "        visualize.display_instances(\n",
    "            image=image.copy(),\n",
    "            boxes=results['rois'],\n",
    "            masks=results['masks'],\n",
    "            class_ids=results['class_ids'],\n",
    "            class_names=dataset_test.class_names,\n",
    "            scores=results['scores'],\n",
    "            title=f\"Test Set (IoU: {iou_score:.3f})\",\n",
    "            ax=ax\n",
    "        )\n",
    "    \n",
    "    # Process validation images\n",
    "    for idx, image_id in enumerate(val_image_ids):\n",
    "        # Load image and ground truth\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(\n",
    "            dataset_val, inference_config, image_id)\n",
    "        \n",
    "        # Get predictions\n",
    "        results = model.detect([image], verbose=0)[0]\n",
    "        \n",
    "        # Prepare masks for comparison\n",
    "        results['masks'], gt_mask = prepare_masks_for_comparison(\n",
    "            results['masks'], \n",
    "            gt_mask,\n",
    "            gt_bbox,\n",
    "            image.shape\n",
    "        )\n",
    "        \n",
    "        # Calculate IoU scores\n",
    "        overlaps = utils.compute_overlaps_masks(results['masks'], gt_mask)\n",
    "        iou_score = overlaps[0][0] if len(overlaps) > 0 else 0\n",
    "        \n",
    "        # Plot ground truth and predictions\n",
    "        ax = axes[1, idx]\n",
    "        visualize.display_instances(\n",
    "            image=image.copy(),\n",
    "            boxes=results['rois'],\n",
    "            masks=results['masks'],\n",
    "            class_ids=results['class_ids'],\n",
    "            class_names=dataset_val.class_names,\n",
    "            scores=results['scores'],\n",
    "            title=f\"Validation Set (IoU: {iou_score:.3f})\",\n",
    "            ax=ax\n",
    "        )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run the comparison\n",
    "compare_test_and_val_predictions(model, dataset_train, dataset_val, num_images=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
